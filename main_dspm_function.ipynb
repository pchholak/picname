{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path as op\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from mne_bids import read_raw_bids, make_bids_basename\n",
    "\n",
    "mne.set_log_level('WARNING')\n",
    "\n",
    "from mne.minimum_norm import (make_inverse_operator, apply_inverse, write_inverse_operator,\n",
    "                             estimate_snr)\n",
    "\n",
    "from mayavi import mlab\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_reject(epochs, plow, phigh, to_plot=True):\n",
    "    \"\"\"\n",
    "    Variance based trial rejection function\n",
    "    \"\"\"\n",
    "    badtrls = []\n",
    "    trl_var, trlindx = np.empty((0,1),'float'), np.arange(0,len(epochs))\n",
    "    for trnum in range(len(epochs)):\n",
    "        trl_var = np.vstack((trl_var, max(np.var(np.squeeze(epochs[trnum].get_data()), axis=1))))\n",
    "    lim1 = (trl_var < np.percentile(trl_var, plow, interpolation='midpoint')).flatten()\n",
    "    lim2 = (trl_var > np.percentile(trl_var, phigh, interpolation='midpoint')).flatten()\n",
    "    outlr_idx = trlindx[lim1].tolist() + trlindx[lim2].tolist()\n",
    "    \n",
    "    if to_plot:\n",
    "        plt.figure(), plt.scatter(trlindx, trl_var, marker='o', s=50, c='g', label='Good trials'),\n",
    "        plt.ylabel('Max. variance across channels-->')\n",
    "        plt.scatter(outlr_idx, trl_var[outlr_idx], marker='o', s=50, c='r', label='Variance based bad trials'),\n",
    "        plt.xlabel('Trial number-->')\n",
    "        plt.scatter(badtrls, trl_var[badtrls], marker='o', s=50, c='orange', label='Manually assigned bad trials')\n",
    "        plt.ylim(min(trl_var)-min(trl_var)*0.01, max(trl_var)+max(trl_var)*0.01), plt.title('Max. variance distribution')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    bad_trials = np.union1d(badtrls, outlr_idx)\n",
    "    print('Removed trials: %s\\n'%bad_trials)\n",
    "    return bad_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_params(iSub, ctrlwin=[-0.5,0], actiwin=[0,1], plow=2, phigh=98):\n",
    "    \"\"\"\n",
    "    Set parameters, directories and filenames for the subject\n",
    "    \"\"\"\n",
    "\n",
    "    par = {'ctrlwin': ctrlwin, 'actiwin': actiwin}\n",
    "    par['plow'], par['phigh'] = plow, phigh\n",
    "\n",
    "    par['data_dir'] = op.expanduser(\"~/data/pic-name-data-bids/\")\n",
    "    sSub = '%02d' % iSub\n",
    "    session , task, run = '01', 'picturenaming', '01'\n",
    "\n",
    "    par['data_path'] = op.join(par['data_dir'], 'MEG')\n",
    "    subjects_dir = op.join(par['data_dir'], 'MRI')\n",
    "    subject = 'sub-' + sSub\n",
    "    par['res_dir'] = op.join(op.expanduser(\"~/research/results/pic_name\"), subject)\n",
    "\n",
    "    par['bids_basename'] = make_bids_basename(subject=sSub, session=session,\n",
    "                                      task=task, run=run)\n",
    "    par['bids_fname'] = par['bids_basename'] + '_meg.fif'\n",
    "    par['bids_path'] = op.join(par['data_path'], subject, 'ses-'+session, 'meg')\n",
    "    par['raw_fname'] = op.join(par['bids_path'], par['bids_fname'])\n",
    "    par['trans_fname'] = op.join(par['bids_path'], subject+'-trans.fif')\n",
    "    par['fwd_fname'] = op.join(par['bids_path'], subject + '-cort-meg-fwd.fif')\n",
    "    par['mrifile'] = op.join(subjects_dir, subject, 'mri/T1.mgz')\n",
    "    par['surffile'] = op.join(subjects_dir, subject, \n",
    "                              'bem/watershed', subject+'_brain_surface')\n",
    "    par['stc_fname'] = op.join(par['res_dir'], 'dspm_' + subject)\n",
    "    par['info'] = mne.io.read_info(par['raw_fname'])\n",
    "    \n",
    "    return par, subject, subjects_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(par, subject, subjects_dir, more_plots=False):\n",
    "    \"\"\"\n",
    "    Preprocess data, load epochs, and get evoked response\n",
    "    \"\"\"\n",
    "    raw = read_raw_bids(par['bids_fname'], par['data_path'],\n",
    "                        extra_params=dict(allow_maxshield=False, preload=True))\n",
    "#     raw.plot();\n",
    "#     raw.annotations.save(op.join(par['bids_path'], subject + '-annot.csv'))\n",
    "    \n",
    "    events, event_id = mne.events_from_annotations(raw)\n",
    "    if more_plots:\n",
    "        mne.viz.plot_events(events, first_samp=0, event_id=event_id,\n",
    "                           equal_spacing=True, show=True)\n",
    "    \n",
    "    picks = mne.pick_types(raw.info, meg=True, eog=True, ecg=True, stim=False, exclude='bads')\n",
    "    \n",
    "    raw.filter(2, 40, picks=picks, filter_length='auto', n_jobs=1,\n",
    "          method='fir', iir_params=None, phase='zero', fir_window='hamming',\n",
    "          fir_design='firwin', skip_by_annotation=('edge', 'bad_acq_skip'),\n",
    "          pad='reflect_limited', verbose=True)\n",
    "    if more_plots:\n",
    "        raw.plot_psd(fmin=0, fmax=45, proj=False, verbose=True)\n",
    "        \n",
    "    epochs = mne.Epochs(raw, events, event_id, par['ctrlwin'][0], par['actiwin'][1],\n",
    "                       baseline=(par['ctrlwin'][0],par['ctrlwin'][1]), picks=picks, \n",
    "                       preload=True, reject=None, flat=None, proj=False, decim=1,\n",
    "                       reject_tmin=None, reject_tmax=None, detrend=None,\n",
    "                       on_missing='error', reject_by_annotation=True,\n",
    "                       verbose=True)\n",
    "    epochs.pick_types(meg=True)\n",
    "    \n",
    "    bad_trials = var_reject(epochs, par['plow'], par['phigh'], to_plot=False)\n",
    "    epochs.drop(bad_trials, reason='variance based rejection', verbose=True)\n",
    "    \n",
    "    evoked = epochs.average()\n",
    "    evoked.plot(spatial_colors=True, gfp=True, proj=False, time_unit='ms')\n",
    "    \n",
    "    return epochs, evoked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_solution(par, subject, subjects_dir, to_make=True):\n",
    "    \"\"\"\n",
    "    Generate forwards solution and source space\n",
    "    \"\"\"\n",
    "    src = mne.setup_source_space(subject, spacing='oct6', subjects_dir=subjects_dir,\n",
    "                                add_dist=False)\n",
    "    \n",
    "    model = mne.make_bem_model(subject=subject, ico=4, conductivity=(0.33,),\n",
    "                          subjects_dir=subjects_dir)\n",
    "    bem = mne.make_bem_solution(model)\n",
    "    \n",
    "    if to_make:\n",
    "        fwd = mne.make_forward_solution(par['info'], trans=par['trans_fname'],\n",
    "                    src=src, bem=bem, meg=True, eeg=False, mindist=5.0, n_jobs=1)\n",
    "        mne.write_forward_solution(par['fwd_fname'], fwd, overwrite=True)\n",
    "    else:\n",
    "        fwd = mne.read_forward_solution(par['fwd_fname'])\n",
    "    \n",
    "    fwd = mne.convert_forward_solution(fwd, surf_ori=True)\n",
    "    \n",
    "    print(\"Leadfield size : %d sensors x %d dipoles\" % fwd['sol']['data'].shape)\n",
    "    \n",
    "    return fwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_solution(par, subject, subjects_dir, epochs, evoked, fwd, to_save=True):\n",
    "    \"\"\"\n",
    "    Compute inverse solution, estimate snr, and show cortical activations\n",
    "    \"\"\"\n",
    "    noise_cov = mne.compute_covariance(epochs,\n",
    "                    tmin=par['ctrlwin'][0], tmax=par['ctrlwin'][1],\n",
    "                    method='empirical', rank='info', verbose=True)\n",
    "    \n",
    "    inverse_operator = make_inverse_operator(par['info'], fwd, noise_cov,\n",
    "                                        loose=0.2, depth=0.8)\n",
    "    \n",
    "    method, lambda2 = \"dSPM\", 1 / 3 ** 2\n",
    "    stc = apply_inverse(evoked, inverse_operator, lambda2, method=method, pick_ori=None)\n",
    "    if to_save:\n",
    "        stc.save(par['stc_fname'])\n",
    "    \n",
    "    stc_abs = np.abs(stc)\n",
    "    _, t_peak = stc_abs.get_peak()\n",
    "    print('Absolute source peaked at = %0.3f' % t_peak)\n",
    "    nt_src_peak = int(t_peak//stc.tstep - stc.times[0]//stc.tstep)\n",
    "    \n",
    "    snr, _ = estimate_snr(evoked, inverse_operator, verbose=True)\n",
    "    nt_snr = np.argmax(snr)\n",
    "    SNR = snr[nt_snr]\n",
    "    print('\\nMax SNR at %0.3f s : %0.3f' % (evoked.times[nt_snr], SNR))\n",
    "    \n",
    "    brain = stc.plot(surface='inflated', hemi='both', subjects_dir=subjects_dir,\n",
    "                time_viewer=False)\n",
    "    brain.set_data_time_index(nt_src_peak)\n",
    "    brain.scale_data_colormap(fmin=4, fmid=7, fmax=10, transparent=True)\n",
    "    brain.show_view('parietal')\n",
    "    \n",
    "    dspm_fname = op.join(par['res_dir'], 'dspm_' + subject + '.png')\n",
    "    brain.save_image(dspm_fname)\n",
    "    mlab.close()\n",
    "    \n",
    "    labels = mne.read_labels_from_annot(subject, 'HCPMMP1', 'both', subjects_dir=subjects_dir)\n",
    "    labels_vis = []\n",
    "    ROI = ['L_V1_ROI-lh', 'R_V1_ROI-rh']\n",
    "    for lbl in labels:\n",
    "        if lbl.name in ROI:\n",
    "            labels_vis.append(lbl)\n",
    "    label = labels_vis[0]\n",
    "    for i in range(1, len(labels_vis)):\n",
    "        label = label + labels_vis[i]\n",
    "    \n",
    "    flip = mne.label_sign_flip(label, inverse_operator['src'])   \n",
    "    \n",
    "    stc_evoked = apply_inverse(evoked, inverse_operator, lambda2, method, pick_ori=\"normal\")\n",
    "    stc_evoked_label = stc_evoked.in_label(label)\n",
    "    label_mean_evoked = np.mean(stc_evoked_label.data, axis=0)\n",
    "    label_mean_evoked_flip = np.mean(flip[:, np.newaxis] * stc_evoked_label.data, axis=0)\n",
    "    \n",
    "    times = 1e3 * stc_evoked.times # times in ms\n",
    "    plt.figure()\n",
    "    h0 = plt.plot(times, stc_evoked_label.data.T, 'k')\n",
    "    h1, = plt.plot(times, label_mean_evoked, 'r', linewidth=3)\n",
    "    h2, = plt.plot(times, label_mean_evoked_flip, 'g', linewidth=3)\n",
    "    plt.legend((h0[0], h1, h2), ('all dipoles in label', 'mean', 'mean with flip'))\n",
    "    plt.xlabel('time (ms)')\n",
    "    plt.ylabel('dSPM value')\n",
    "    plt.show()\n",
    "    plt.savefig(op.join(par['res_dir'], 'evoked_label_' + subject + '.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dspm(iSub):\n",
    "    badtrls = []\n",
    "    par, subject, subjects_dir = set_params(iSub)\n",
    "    epochs, evoked = preprocess(par, subject, subjects_dir)\n",
    "    fwd = forward_solution(par, subject, subjects_dir)\n",
    "    inverse_solution(par, subject, subjects_dir, epochs, evoked, fwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 2 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 2.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 1651 samples (1.651 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-fd4e5e106831>:6: RuntimeWarning: The unit for channel(s) STI101, STI201, STI301 has changed from V to NA.\n",
      "  extra_params=dict(allow_maxshield=False, preload=True))\n",
      "/Users/chholak/anaconda3/lib/python3.7/site-packages/mne_bids/utils.py:635: UserWarning: Did not find any electrodes.tsv file associated with sub-08_ses-01_task-picturenaming_run-01_meg.fif.\n",
      "\n",
      "The search_str was \"/Users/chholak/data/pic-name-data-bids/MEG/sub-08/**/sub-08_ses-01*electrodes.tsv\"\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "Loading data for 104 events and 1501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Removed trials: [ 19.  24.  29.  63.  72. 101.]\n",
      "\n",
      "Dropped 6 epochs: 19.0, 24.0, 29.0, 63.0, 72.0, 101.0\n",
      "Leadfield size : 306 sensors x 24588 dipoles\n",
      "Computing rank from data with rank='info'\n",
      "    MEG: rank 71 after 0 projectors applied to 306 channels\n",
      "    Setting small MEG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 306 -> 71\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Number of samples used : 49098\n",
      "[done]\n",
      "Absolute source peaked at = 0.209\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 98\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 71 (235 small eigenvalues omitted)\n",
      "Picked 306 channels from the data\n",
      "Effective nchan = 306 - 235 = 71\n",
      "\n",
      "Max SNR at 0.202 s : 3.378\n",
      "colormap sequential: [4.00e+00, 7.00e+00, 1.00e+01] (transparent)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chholak/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:63: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "/Users/chholak/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:63: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "/Users/chholak/anaconda3/lib/python3.7/site-packages/pyface/ui/qt4/gui.py:85: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  QtCore.QCoreApplication.processEvents(events)\n"
     ]
    }
   ],
   "source": [
    "run_dspm(iSub=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
